{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "from osgeo import osr\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "def imshow(image, show_axes = False, quiet = False):\n",
    "    if len(image.shape) == 3:\n",
    "      # Height, width, channels\n",
    "      # Assume BGR, do a conversion since \n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "      # Height, width - must be grayscale\n",
    "      # convert to RGB, since matplotlib will plot in a weird colormap (instead of black = 0, white = 1)\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    # Draw the image\n",
    "    plt.imshow(image)\n",
    "    if not show_axes:\n",
    "        # We'll also disable drawing the axes and tick marks in the plot, since it's actually an image\n",
    "        plt.axis('off')\n",
    "    if not quiet:\n",
    "        # Make sure it outputs\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal:\n",
    "This note book process MET videos.\n",
    "1. Separate the image into three scenes based on surface region\n",
    "2. Give each prediction point a region indicator\n",
    "3. Merge the transformation to one single dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create three polygons in the image (done in PS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "frame_folder = \"../../_data/02_siteplan/sample_frames/current_sample\"\n",
    "ref_name = \"20100612-082221b02_3446.jpg\"\n",
    "# w,h = 720,480\n",
    "\n",
    "# # 20100612-082221b15\n",
    "# region1 = Polygon([(303.6, 359.5), (720,316.5), (720, 480),(0, 480), (0, 343.5)]) # image space may have reversed y-axis\n",
    "\n",
    "# region2 = Polygon([(303.6, 359.5), (327.6, 214.5), (452.6, 214.5), (720, 316.5)])\n",
    "# region3 = Polygon([(303.6, 359.5), (327.6, 214.5), (0, 203.5), (0, 343.5)])\n",
    "# regiondf = gpd.GeoDataFrame({\n",
    "#     \"region\":[\"ground\", \"stair_right\", \"stair_left\"],\n",
    "#     \"geometry\":[region1, region2, region3]\n",
    "# }, geometry=\"geometry\")\n",
    "# regiondf.plot()\n",
    "\n",
    "imgpath = os.path.join(frame_folder, ref_name)\n",
    "# imshow(imgpath, show_axes = False, quiet = False)\n",
    "\n",
    "image  = cv2.cvtColor(cv2.imread(imgpath), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "pts1 = np.array([[303.6, 359.5], [720,316.5], [720, 480],[0, 480], [0, 343.5]],\n",
    "               np.int32)\n",
    "pts2 = np.array([[303.6, 359.5], [327.6, 214.5], [452.6, 214.5], [720, 300.5],[720, 316.5]], np.int32)\n",
    "pts3 = np.array([[303.6, 359.5], [327.6, 214.5], [0, 203.5], [0, 343.5]], np.int32)\n",
    "thickness = 2\n",
    "color = (255, 0, 0)\n",
    "isClosed = True\n",
    "\n",
    "ptls = [pts1, pts2, pts3]\n",
    "\n",
    "for pts in ptls:\n",
    "    pts = pts.reshape((-1, 1, 2))\n",
    "    image = cv2.polylines(image, [pts],\n",
    "                    isClosed, color, thickness)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "plt.imshow(image)\n",
    "cv2.imwrite(os.path.join(frame_folder, ref_name.split(\".\")[0]+\"split.jpg\"), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regiondf = gpd.GeoDataFrame({\n",
    "    \"region\":[\"ground\", \"right_step\", \"left_step\"],\n",
    "    \"geometry\":[Polygon([(x,y) for x,y in pts]) for pts in ptls]\n",
    "}, geometry=\"geometry\")\n",
    "regiondf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image and plot the region of interest on the image\n",
    "frame_folder = \"../../_data/02_siteplan/sample_frames/current_sample\"\n",
    "ref_name = \"20100612-120118b01_3446.jpg\"\n",
    "\n",
    "imgpath = os.path.join(frame_folder, ref_name)\n",
    "# imshow(imgpath, show_axes = False, quiet = False)\n",
    "\n",
    "image  = cv2.cvtColor(cv2.imread(imgpath), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "pts1 = np.array([[360.6, 352.5], [720,316.5], [720, 480],[0, 480], [0, 335.5]],\n",
    "               np.int32)\n",
    "pts2 = np.array([[360.6, 352.5], [374.6, 215.5], [477.6, 211.5], [720, 288.5],[720, 316.5]], np.int32)\n",
    "pts3 = np.array([[360.6, 352.5], [374.6, 215.5], [0, 220.5], [0, 335.5]], np.int32)\n",
    "thickness = 2\n",
    "color = (255, 0, 0)\n",
    "isClosed = True\n",
    "\n",
    "ptls = [pts1, pts2, pts3]\n",
    "\n",
    "for pts in ptls:\n",
    "    pts = pts.reshape((-1, 1, 2))\n",
    "    image = cv2.polylines(image, [pts],\n",
    "                    isClosed, color, thickness)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "plt.imshow(image)\n",
    "# save this image as the reference file\n",
    "cv2.imwrite(os.path.join(frame_folder, ref_name.split(\".\")[0]+\"split.jpg\"), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regiondf = gpd.GeoDataFrame({\n",
    "    \"region\":[\"ground\", \"right_step\", \"left_step\"],\n",
    "    \"geometry\":[Polygon([(x,y) for x,y in pts]) for pts in ptls]\n",
    "}, geometry=\"geometry\")\n",
    "regiondf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pts = pts1\n",
    "\n",
    "# mask = np.zeros(image.shape[:2], np.uint8)\n",
    "# cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "# dst = cv2.bitwise_and(image, image, mask=mask)\n",
    "# # bg = np.ones_like(image, np.uint8)*255\n",
    "# # cv2.bitwise_not(bg,bg, mask=mask)\n",
    "# # dst2 = bg+ dst\n",
    "# plt.imshow(dst)\n",
    "# plt.imshow(dst2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Put all prediction points results to the three regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load one sample prediction\n",
    "# result_folder = \"../_data/06_attr_result/\"\n",
    "# videoname = \"20100612-120118b02\"\n",
    "# # videoname = \"20100521-074701b03\"\n",
    "# predpath = os.path.join(result_folder, f'{videoname}.csv')\n",
    "# trace = pd.read_csv(predpath)\n",
    "# trace.rename(columns = {\"x\":\"bbox0\", \"y\":\"bbox1\", \"w\":\"bbox2\", \"h\":\"bbox3\"}, inplace = True)\n",
    "# trace['loc_x'] = (trace['bbox0'] + trace['bbox0'] + trace['bbox2'])/2\n",
    "# trace['loc_y'] = (trace['bbox1'] + trace['bbox3'])\n",
    "# # generate point at image space\n",
    "# tracept = gpd.GeoDataFrame(\n",
    "#     trace,\n",
    "#     geometry = gpd.points_from_xy(trace.loc_x, trace.loc_y)\n",
    "# )\n",
    "# # spatial join to get region name\n",
    "# tracept_update = gpd.sjoin(tracept, regiondf, how = 'inner')\n",
    "# print(\"region assigned\")\n",
    "\n",
    "# tracept_update.drop(\"geometry\", axis = 1, inplace = True)\n",
    "# del tracept\n",
    "# import gc\n",
    "# gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get projection by each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proj_matrix(ref):\n",
    "    '''\n",
    "\n",
    "    pts_src and pts_dst are numpy arrays of points\n",
    "\n",
    "    in source and destination images. We need at least\n",
    "\n",
    "    corresponding points.\n",
    "\n",
    "    '''\n",
    "    try:\n",
    "        pts_src = np.array([(x,y) for x,y in zip(ref['sourceX'], -1*ref['sourceY'])])\n",
    "    except:\n",
    "        pts_src = np.array([(x,y) for x,y in zip(ref['pixelX'], -1*ref['pixelY'])])\n",
    "\n",
    "    pts_dst  = np.array([(x,y) for x,y in zip(ref['mapX'], ref['mapY'])])\n",
    "\n",
    "    h, status = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "    '''\n",
    "    The calculated homography can be used to warp\n",
    "\n",
    "    the source image to destination. Size is the\n",
    "\n",
    "    size (width,height) of im_dst\n",
    "    '''\n",
    "    return h\n",
    "\n",
    "def projectPlan(df, h, x, y):\n",
    "    pts = df[[x, y]].values\n",
    "    ## (n, 1, 2)\n",
    "    pts1 = pts.reshape(-1,1,2).astype(np.float32)\n",
    "    dst1 = cv2.perspectiveTransform(pts1, h)\n",
    "    return dst1\n",
    "\n",
    "\n",
    "def pixel2coord(col, row, ds):\n",
    "    # 3. transform to 2326 geolocation\n",
    "    c, a, b, f, d, e = ds.GetGeoTransform()\n",
    "    \"\"\"Returns global coordinates to pixel center using base-0 raster index\"\"\"\n",
    "    xp = a * col + b * row + a * 0.5 + b * 0.5 + c\n",
    "    yp = d * col + e * row + d * 0.5 + e * 0.5 + f\n",
    "    return(xp, yp)\n",
    "\n",
    "\n",
    "# bbox0, bbox1, bbox2, bbox3 : x1, y1, w, h\n",
    "# Replace this part for other data\n",
    "# Trace\n",
    "\n",
    "# check gender distribution within one track_id\n",
    "# set attribute list\n",
    "def get_attr(trace):\n",
    "    attribute_ls = ['gender', 'age', 'side', 'glasses', 'hat', 'hold_objects_in_front',\n",
    "        'bag', 'upper', 'lower', 'boots']\n",
    "    # for each track_id only keep one major attribute\n",
    "    for attr in attribute_ls:\n",
    "        trace[attr] = trace.groupby(\"track_id\")[attr].transform(lambda x: x.mode()[0])\n",
    "    # trace[trace[\"track_id\"] == 1].groupby([\"gender\"]).size()\n",
    "\n",
    "    attr_df = trace.drop_duplicates(\"track_id\")[attribute_ls+[\"track_id\"]]\n",
    "    return attr_df\n",
    "\n",
    "def getclean(trace, h, epsg, videoname):\n",
    "\n",
    "\n",
    "    \n",
    "    trs2 = projectPlan(trace, h, 'loc_x', 'loc_y')\n",
    "    trace[f'x_{epsg}'] = trs2[:,:,0]\n",
    "    trace[f'y_{epsg}'] = trs2[:,:,1] \n",
    "    \n",
    "    trace['video_id'] = videoname\n",
    "\n",
    "        # smoothe the x, y for every 30 frames\n",
    "    # trace['moving_x'] = trace.groupby('track_id')[f'x_{epsg}'].transform(lambda x: x.rolling(30, 1).mean())\n",
    "    # trace['moving_y'] = trace.groupby('track_id')[f'y_{epsg}'].transform(lambda x: x.rolling(30, 1).mean())\n",
    "    # attribute_ls = ['gender', 'age', 'side', 'glasses', 'hat', 'hold_objects_in_front',\n",
    "    #     'bag', 'upper', 'lower', 'boots']\n",
    "    \n",
    "    cols = ['video_id',\n",
    "        'frame_id',\n",
    "                  'track_id','loc_x', 'loc_y',\n",
    "                     f'x_{epsg}', f'y_{epsg}', # reference geo in HK\n",
    "                     'category_id',\n",
    "                     \"score\",\n",
    "                     \"region\"\n",
    "                  ]\n",
    "    cols_keep = [x for x in trace.columns if x in cols]\n",
    "    return trace[cols_keep]\n",
    "            \n",
    "\n",
    "def getgdf(traceDF, epsg, tail = True, length = 3):\n",
    "    \"\"\"length: refers to the second of lagging tail we want to see\"\"\"\n",
    "    # smoothe the x, y for every 30 frames\n",
    "    traceDF['moving_x'] = traceDF.groupby('track_id')[f'x_{epsg}'].transform(lambda x: x.rolling(5, 1).mean())\n",
    "    traceDF['moving_y'] = traceDF.groupby('track_id')[f'y_{epsg}'].transform(lambda x: x.rolling(5, 1).mean())\n",
    "\n",
    "    traceGDF = gpd.GeoDataFrame(traceDF, geometry = [Point(x,y) for x,y in zip(traceDF[f'x_{epsg}'],\n",
    "                                                                               traceDF[f'y_{epsg}'])])\n",
    "    traceGDF.crs = f\"EPSG:{epsg}\"\n",
    "    traceGDF = traceGDF.to_crs('EPSG:4326')\n",
    "    traceGDF['lat'] = traceGDF['geometry'].y\n",
    "    traceGDF['lon'] = traceGDF['geometry'].x\n",
    "    \n",
    "    traceGDF['lat_moving'] = traceGDF.groupby('track_id')['lat'].transform(lambda x: x.rolling(5, 1).mean())\n",
    "    traceGDF['lon_moving'] = traceGDF.groupby('track_id')['lon'].transform(lambda x: x.rolling(5, 1).mean())\n",
    "    return traceGDF\n",
    "\n",
    "# drop the outlier automatically\n",
    "def find_outliers_IQR(df, field, low = 0.25, high = 0.75):\n",
    "\n",
    "   q1=df[field].quantile(low)\n",
    "\n",
    "   q3=df[field].quantile(high)\n",
    "\n",
    "   IQR=q3-q1\n",
    "\n",
    "   outliers = df[((df[field]<(q1-1.5*IQR)) | (df[field]>(q3+1.5*IQR)))]\n",
    "\n",
    "   keep = df[((df[field]>=(q1-1.5*IQR)) & (df[field]<=(q3+1.5*IQR)))].reset_index(drop = True)\n",
    "\n",
    "   return outliers, keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proj_video_archive(videoname, ref):\n",
    "    \"\"\"For new videos, we extract the detection results from tracks\"\"\"\n",
    "    result_folder = \"../../_data/06_attr_result/\"\n",
    "    predpath = os.path.join(result_folder, f'{videoname}.csv')\n",
    "    trace = pd.read_csv(predpath)\n",
    "    trace['ratio'] = trace['w']/trace['h']\n",
    "    _, trace = find_outliers_IQR(trace, 'ratio', 0.15, 0.85)\n",
    "    trace.rename(columns = {\"x\":\"bbox0\", \"y\":\"bbox1\", \"w\":\"bbox2\", \"h\":\"bbox3\"}, inplace = True)\n",
    "    trace['loc_x'] = (trace['bbox0'] + trace['bbox0'] + trace['bbox2'])/2\n",
    "    trace['loc_y'] = (trace['bbox1'] + trace['bbox3'])\n",
    "    \n",
    "    tracept = gpd.GeoDataFrame(\n",
    "        trace,\n",
    "        geometry = gpd.points_from_xy(trace.loc_x, trace.loc_y)\n",
    "    )\n",
    "    # spatial join to get region name\n",
    "    tracept_update = gpd.sjoin(tracept, regiondf, how = 'inner') # regiondf currently is a global variable. needs to be updated to match different view angle\n",
    "    print(\"region assigned\")\n",
    "\n",
    "    trace = tracept_update.drop(\"geometry\", axis = 1)\n",
    "    del tracept\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    h = get_proj_matrix(ref)\n",
    "# # Set up projection for New York State Plane\n",
    "# set up to match the projection of the reference data\n",
    "    # epsg = 3857  #2263\n",
    "    epsg = videopath_sel[videopath_sel['video_id']==videoname]['ref_epsg'].values[0]\n",
    "    traceDF = getclean(trace, h, epsg, videoname)\n",
    "    traceGDF = getgdf(traceDF, epsg)\n",
    "    \n",
    "    attr_df = get_attr(traceDF)\n",
    "\n",
    "    # drop outliers\n",
    "    _, traceGDF_keep = find_outliers_IQR(traceGDF, \"moving_x\")\n",
    "    \n",
    "    traceGDF = traceGDF_keep.drop([\"gender\",\"age\"], axis = 1).merge(attr_df[[\"track_id\", \"gender\", \"age\"]], on = \"track_id\", how = \"left\")\n",
    "    \n",
    "    return traceGDF\n",
    "\n",
    "def getbasics(file_path):\n",
    "    video = cv2.VideoCapture(file_path)\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    print('frames per second =',fps)\n",
    "    size = (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    print('frames size =',size)\n",
    "    # video.release()\n",
    "    return video, fps, size\n",
    "\n",
    "# read in the points\n",
    "def get_ref(ref_path):\n",
    "    # with open(ref_folder + ref_video + f\"_3446_modified.tif.points\", \"r\") as f:\n",
    "    with open(os.path.join(ref_folder, ref_path), \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.strip().split(\",\") for line in lines]\n",
    "    # convert to dataframe\n",
    "    ref = pd.DataFrame(lines[1:], columns = lines[0])\n",
    "    # convert to float\n",
    "    ref = ref.astype(float)\n",
    "    return ref\n",
    "\n",
    "\n",
    "# def get_all_info(videoname, useimage = True):\n",
    "#     \"\"\"One reference file version\"\"\"\n",
    "#     ref_path = videopath_sel[videopath_sel['video_id']==videoname]['ref_path'].values[0]\n",
    "#     ref = get_ref(ref_path)\n",
    "\n",
    "#     traceGDF_keep = get_proj_video(videoname, ref)\n",
    "#     if \"category_id\" in traceGDF_keep.columns:\n",
    "#         traceGDF_people = traceGDF_keep[(traceGDF_keep[\"category_id\"] == 0)&(traceGDF_keep[\"score\"]>0.1)].reset_index(drop = True)\n",
    "#         return traceGDF_people\n",
    "#     else:\n",
    "#         return traceGDF_keep\n",
    "    \n",
    "    \n",
    "def get_all_info(videoname, useimage = True):\n",
    "    \"\"\"Three reference files version\"\"\"\n",
    "    ref_path = videopath_sel[videopath_sel['video_id']==videoname]['ref_path'].values[0]\n",
    "    ref_ls = []\n",
    "    traceGDF_ls = []\n",
    "    for reg in [\"ground\", \"right_step\", \"left_step\"]:\n",
    "        if \"ground\" in ref_path:\n",
    "            ref = get_ref(ref_path.replace(\"ground\", reg))\n",
    "            ref_ls.append(ref)\n",
    "\n",
    "        traceGDF_keep = get_proj_video(videoname, ref)\n",
    "        # if \"category_id\" in traceGDF_keep.columns:\n",
    "        # traceGDF_people = traceGDF_keep[(traceGDF_keep[\"category_id\"] == 0)&(traceGDF_keep[\"score\"]>0.1)].reset_index(drop = True)\n",
    "        traceGDF_keep = traceGDF_keep[traceGDF_keep['region']==reg].reset_index(drop = True)\n",
    "        traceGDF_ls.append(traceGDF_keep)\n",
    "    traceGDF_ls = pd.concat(traceGDF_ls).reset_index(drop = True)\n",
    "    return traceGDF_ls\n",
    "    \n",
    "    \n",
    "def get_frame_num(time_str, fps = 29.97002997002997):\n",
    "    try:\n",
    "        time = time_str.split(\" \")[0][3:].split(\":\")\n",
    "        minute = int(time[0])\n",
    "        second = int(time[1])\n",
    "        frame = minute*60*fps + second*fps\n",
    "        return int(frame)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "frame_folder = \"../../_data/02_siteplan/sample_frames/current_sample\"\n",
    "tiff_folder = \"../../_data/02_siteplan/geo_tiff\"\n",
    "ref_folder = \"../../_data/02_siteplan/gcp_pt/\"\n",
    "frames = os.listdir(frame_folder)\n",
    "refs = os.listdir(ref_folder)\n",
    "# reference points\n",
    "# create a dataframe to store all video names for each location\n",
    "# videoname = \"B16_G10_Env25_0001\" # historical bryant park\n",
    "# videoname = \"20081008-141944b03\" # current bryant park\n",
    "\n",
    "# videoname = \"20100521-074701b06\" # downtown crossing example\n",
    "# frame_start = \"3446\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integrate the start and end timestamp\n",
    "videopath = pd.read_csv(\"../../_data/00_raw/_video_meta/video_path_0509.csv\")\n",
    "videopath['video_id'] = videopath['video_name'].apply(lambda x: x.split(\".\")[0])\n",
    "# videopath_sel = videopath[videopath['scene'].isin([2,3])]\n",
    "videopath_sel = videopath[~videopath['ref_path'].isna()].reset_index(drop = True)\n",
    "videopath_sel['first_effective_time'].unique()\n",
    "videopath_sel['first_effective_time'] = videopath_sel['first_effective_time'].fillna(\"12:00:00 AM\")\n",
    "videopath_sel['frame_start'] = videopath_sel['first_effective_time'].apply(lambda x: get_frame_num(x))\n",
    "\n",
    "# videopath_sel['last_effective_time'] = videopath_sel['last_effective_time'].fillna(\"12:00:00 AM\")\n",
    "videopath_sel['frame_end'] = videopath_sel['last_effective_time'].apply(lambda x: get_frame_num(x))\n",
    "videopath_sel['frame_end'] = videopath_sel['frame_end'].fillna(videopath_sel['length'])\n",
    "videopath_sel['ref_epsg'] = videopath_sel['ref_epsg'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# scene_proj = {\n",
    "#     0:None,\n",
    "#     1:None,\n",
    "#     2: \"20100521-074701b06\",\n",
    "#     3: \"20100521-115755b02\",\n",
    "    \n",
    "# }\n",
    "# videopath_sel['ref_frame'] = videopath_sel['scene'].apply(lambda x: scene_proj[x])\n",
    "\n",
    "# load finished prediction names\n",
    "exportfolder = \"../../_data/06_attr_result\"\n",
    "finished = os.listdir(exportfolder)\n",
    "videopath_sel['finished'] = videopath_sel['video_id'].apply(lambda x: x+\".csv\" in finished)\n",
    "\n",
    "videopath_sel.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = \"20100612-120118\" # use no attribute detection results\n",
    "# group = \"20100612-082221\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "outputfolder = \"../../_data/05_tracking_result_projected/step0_no_attr_prj\"\n",
    "if not os.path.exists(outputfolder):\n",
    "    os.makedirs(outputfolder)\n",
    "# now_processing = videopath_sel[(videopath_sel[\"finished\"]==True)\\\n",
    "#     &(videopath_sel['video_location']==\"Met Steps videos (NEW)\")\\\n",
    "#         &(videopath_sel['ref_path'].str.contains('20100612-082221b02'))]\\\n",
    "#     .reset_index(drop = True)\n",
    "now_processing = videopath_sel[videopath_sel['ref_path'].str.contains(group)].reset_index(drop = True)\n",
    "now_processingls = now_processing['video_id'].values\n",
    "now_processingls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now_processingls = ['20100612-120118b03.txt']\n",
    "def get_proj_video(videoname, ref):\n",
    "    \"\"\"For new videos, we extract the detection results from tracks\"\"\"\n",
    "    result_folder = \"/Users/yuan/Dropbox (MIT)/whyte_CV/_data/03_tracking_result/_current_video_no_attr\"\n",
    "    predpath = os.path.join(result_folder, f'{videoname}.txt')\n",
    "    trace = pd.read_csv(predpath, sep = '\\t', header = None)\n",
    "    trace.columns = [ \"x1\", \"y1\", \"x2\", \"y2\", \"track_id\", \"frame_id\"]\n",
    "    trace['w'] = trace['x2'] - trace['x1']\n",
    "    trace['h'] = trace['y2'] - trace['y1']\n",
    "    trace['ratio'] = trace['w']/trace['h']\n",
    "    _, trace = find_outliers_IQR(trace, 'ratio', 0.15, 0.85)\n",
    "    trace.rename(columns = {\"x1\":\"bbox0\", \"y1\":\"bbox1\", \"w\":\"bbox2\", \"h\":\"bbox3\"}, inplace = True)\n",
    "\n",
    "    trace['loc_x'] = (trace['bbox0'] + trace['bbox0'] + trace['bbox2'])/2\n",
    "    trace['loc_y'] = (trace['bbox1'] + trace['bbox3'])\n",
    "        \n",
    "    tracept = gpd.GeoDataFrame(\n",
    "        trace,\n",
    "        geometry = gpd.points_from_xy(trace.loc_x, trace.loc_y)\n",
    "    )\n",
    "    # spatial join to get region name\n",
    "    tracept_update = gpd.sjoin(tracept, regiondf, how = 'inner') # regiondf currently is a global variable. needs to be updated to match different view angle\n",
    "    print(\"region assigned\")\n",
    "\n",
    "    trace = tracept_update.drop(\"geometry\", axis = 1)\n",
    "    del tracept\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    h = get_proj_matrix(ref)\n",
    "# # Set up projection for New York State Plane\n",
    "# set up to match the projection of the reference data\n",
    "    # epsg = 3857  #2263\n",
    "    epsg = videopath_sel[videopath_sel['video_id']==videoname]['ref_epsg'].values[0]\n",
    "    traceDF = getclean(trace, h, epsg, videoname)\n",
    "    traceGDF = getgdf(traceDF, epsg)\n",
    "    \n",
    "    # attr_df = get_attr(traceDF)\n",
    "\n",
    "    # drop outliers\n",
    "    _, traceGDF_keep = find_outliers_IQR(traceGDF, \"moving_x\")\n",
    "    \n",
    "\n",
    "    \n",
    "    return traceGDF_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "for videoname in tqdm(['20100612-120118b04']):\n",
    "    print(videoname)\n",
    "    traceGDF_people = get_all_info(videoname,  \n",
    "                                useimage = False)\n",
    "    file_path = videopath[videopath['video_id'] == videoname]['videopath'].values[0]\n",
    "    # video, fps, size = getbasics(file_path)\n",
    "    fps = videopath[videopath['video_id'] == videoname]['fps'].values[0]\n",
    "    \n",
    "    # only keep the frame_id after the first desired frame\n",
    "    first_frame_sel = videopath_sel[videopath_sel['video_id']== videoname]['frame_start'].values[0]\n",
    "    # last_frame_sel = videopath_sel[videopath_sel['video_id']== videoname]['frame_end'].values[0]\n",
    "    traceGDF_people = traceGDF_people[(traceGDF_people['frame_id']>=first_frame_sel)].reset_index(drop = True)\n",
    "    \n",
    "    traceGDF_people[\"second\"] = traceGDF_people[\"frame_id\"]//fps\n",
    "    # sample = traceGDF_people[traceGDF_people[\"second\"]<20] # pick 20 seconds sample\n",
    "    loc_name = videopath[videopath['video_id'] == videoname]['video_location'].values[0]\n",
    "    destfolder = os.path.join(outputfolder, loc_name)\n",
    "    if not os.path.exists(destfolder):\n",
    "        os.makedirs(destfolder)\n",
    "    traceGDF_people.drop(\"geometry\", axis = 1).to_csv(os.path.join(destfolder, f\"{videoname}_projected.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20100612-082221b02_3446_ground_modified.tif"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test draw image to see the detection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = gpd.GeoDataFrame(temp, geometry=gpd.points_from_xy(temp.lon, temp.lat))\n",
    "temp.crs = \"EPSG:4326\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical videofolder:\n",
    "# file_path = f\"../_data/00_raw/_mp4/videos_old_highres/{videoname}.mp4\"\n",
    "# current videofolder:\n",
    "# file_path = f\"../_data/00_raw/videos_current_highres/bryant_park/{videoname}.avi\"\n",
    "videoname = \"20100612-120118b01\"\n",
    "videopath = pd.read_csv(\"../../_data/00_raw/_video_meta/video_path_0509.csv\")\n",
    "videopath['video_id'] = videopath['video_name'].apply(lambda x: x.split(\".\")[0])\n",
    "file_path = videopath[videopath['video_id'] == videoname]['videopath'].values[0]\n",
    "file_path = \"../\"+file_path\n",
    "file_path = \"/Users/yuan/Dropbox (MIT)/whyte_CV/_data/00_raw/videos_current_highres/Met Steps videos (NEW)/20100521-115754-01/20100612-120118b01.avi\"\n",
    "video, fps, size = getbasics(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "frame_id = 3000\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "ret, frame = video.read()\n",
    "# plot the frame\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "fig = plt.subplots(figsize = (10,10))\n",
    "plt.imshow(frame)\n",
    "\n",
    "# load traceGDF_people for this video\n",
    "loc_name = \"Met Steps videos (NEW)\"\n",
    "destfolder = os.path.join(outputfolder, loc_name)\n",
    "filepath = os.path.join(destfolder, f\"{videoname}_projected.csv\")\n",
    "traceGDF_people = pd.read_csv(filepath)\n",
    "temp = traceGDF_people[traceGDF_people[\"frame_id\"] == frame_id]\n",
    "plt.scatter(\n",
    "    temp[\"loc_x\"], \n",
    "    temp[\"loc_y\"], color = 'red')\n",
    "\n",
    "# export the x,y coordinates to csv of this one frame\n",
    "# temp[[\"geometry\",\"track_id\"]].to_file(f\"../_data/05_demo/2023-04-30/{videoname}_frame_{frame_id}.geojson\", \n",
    "# driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp[[\"geometry\",\"track_id\"]].to_file(f\"../_data/05_demo/2023-04-30/{videoname}_frame_{frame_id}.geojson\", \n",
    "# driver = \"GeoJSON\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualize the track examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videopath = pd.read_csv(\"../../_data/00_raw/_video_meta/video_path.csv\")\n",
    "outputfolder = \"../../_data/05_tracking_result_projected/step0_no_attr_prj\"\n",
    "# now_processing = videopath_sel[videopath_sel[\"finished\"]==True].reset_index(drop = True)\n",
    "# select one video for trace visualization\n",
    "\n",
    "destfolder = os.path.join(outputfolder, loc_name)\n",
    "trace = pd.read_csv(os.path.join(destfolder, f\"{videoname}_projected.csv\"))\n",
    "traceGDF = gpd.GeoDataFrame(trace, geometry=gpd.points_from_xy(trace.lon, trace.lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, traceGDF = find_outliers_IQR(traceGDF, \"moving_x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsg = 3857\n",
    "\n",
    "# plot a trace sample\n",
    "temp = traceGDF[traceGDF[\"frame_id\"]<4000]\n",
    "_, temp = find_outliers_IQR(temp, \"moving_x\")\n",
    "# construct lines\n",
    "tracesum = temp.groupby(\"track_id\").size().reset_index().rename(columns = {0:\"count\"})\n",
    "trackidls = tracesum[tracesum[\"count\"]>10][\"track_id\"].unique()\n",
    "geo_df2 = temp[temp[\"track_id\"].isin(trackidls)].sort_values(\"frame_id\").reset_index(drop = True)\\\n",
    ".groupby(['track_id',\"gender\", \"age\"])['geometry'].apply(lambda x: LineString(x.tolist())).reset_index()\n",
    "\n",
    "geo_df2.crs = \"EPSG:4326\"\n",
    "geo_df2 = geo_df2.to_crs(f\"EPSG:{epsg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert and print pass\n",
    "assert geo_df2.crs == f\"EPSG:{epsg}\", \"crs is not correct\"\n",
    "\n",
    "geo_df2.plot(column = \"gender\", figsize = (10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df2.to_file(\"MET steps.geojson\", driver = \"GeoJSON\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export at h3 level for occupation rate estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 29\n",
    "traceGDF[\"second_from_start\"] = traceGDF[\"frame_id\"]/fps\n",
    "\n",
    "traceGDF[\"minute\"] = traceGDF[\"second_from_start\"]//60\n",
    "traceGDF[\"hour\"] = traceGDF[\"second_from_start\"]//3600\n",
    "traceGDF[\"second\"] = traceGDF[\"second_from_start\"]- traceGDF[\"hour\"]*3600 - traceGDF[\"minute\"]*60\n",
    "traceGDF[\"timestamp\"] = \"2008-10-08\"+\" \" + traceGDF[\"hour\"].astype(str) + \":\"+traceGDF[\"minute\"].astype(str).str.zfill(2)\\\n",
    "    +\":\"+traceGDF[\"second\"].astype(str)\n",
    "traceGDF[\"timestamp\"] = pd.to_datetime(traceGDF[\"timestamp\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert all dectection to hexagon 15 for aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traceGDF.to_file(os.path.join(clipfolder, f\"{videoname[:-4]}_prediction_with_attr.geojson\"), driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traceGDF = pd.read_csv(r\"D:\\Dropbox (MIT)\\whyte_CV\\_data\\05_tracking_result_projected\\step0_attr_prj\\20081008-141944b03_projected_with_attr.csv\")\n",
    "traceGDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h3 import h3\n",
    "res = 15\n",
    "traceGDF[f\"h3_{res}\"] = traceGDF.apply(lambda row: h3.geo_to_h3(row[\"lat\"], row[\"lon\"], res), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count people per h3 id per minute per gender\n",
    "\n",
    "countpeople_gender = traceGDF.groupby([f\"h3_{res}\",\"gender\"])[\"track_id\"].nunique().reset_index()\\\n",
    "    .pivot(columns = \"gender\", index = [\"h3_15\"], values = \"track_id\").reset_index().fillna(0)\n",
    "countpeople_gender\n",
    "# countpeople_gender.to_csv(os.path.join(outfolder, f\"{videoname}_prediction_aggregation.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countpeople_age = traceGDF.groupby([f\"h3_{res}\",\"age\"])[\"track_id\"].nunique().reset_index()\\\n",
    "    .pivot(columns = \"age\", index = [\"h3_15\"], values = \"track_id\").reset_index().fillna(0)\n",
    "countpeople_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = countpeople_gender.merge(countpeople_age, on = [\"h3_15\"], how = \"outer\")\n",
    "summary[\"total\"] = summary[\"Female\"]+summary[\"Male\"]\n",
    "outfolder = \"../_data/05_tracking_result_projected\"\n",
    "summary.to_csv(os.path.join(outfolder, f\"{videoname}_prediction_aggregation_overall.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = traceGDF_keep.groupby(\"track_id\").size().reset_index()\n",
    "summary[summary[0]>fps].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countpeople = traceGDF_keep.groupby([f\"h3_{res}\"])[\"track_id\"].nunique().reset_index()\n",
    "countpeople.to_csv(os.path.join(clipfolder, f\"{videoname}_prediction_aggregation_all.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0fdb9f36a2fa6c0d80c32614b079baf171674cda7a504cb8efc605d7162d1d77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
