{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1293dad1-2f14-4316-8dc9-9d3553956038",
   "metadata": {},
   "source": [
    "# Generate a sample frame for creating image pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39599fe4-44d9-4385-93ef-a087126557f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Video\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "from cv2 import __version__\n",
    "__version__\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "# folder = \"../_data/_raw/videos/Box11\"\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecab572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "videofolder = \"../../_data/00_raw/videos_current_highres/\"\n",
    "sample_frame_folder  = \"../../_data/02_siteplan/sample_frames/current_sample\"\n",
    "exportfolder = \"../../_data/03_tracking_result/_current_attr_result\"\n",
    "predictfolder = \"../../_data/03_tracking_result/_current_attr_result/_raw_prediction\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0d0bce6",
   "metadata": {},
   "source": [
    "# Steps\n",
    "1. Create a list of all the videos\n",
    "2. Annotate if they have been processed or not\n",
    "3. Create a folder for sample image starting time\n",
    "4. Create a list for all scenes partitioned\n",
    "5. Get a sample image whenever the camera moved\n",
    "6. Convert the raw prediction to combined attribute file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6220bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# list all videos in the folder\n",
    "videols = glob.glob(videofolder + \"**/*.avi\", \n",
    "                    recursive = True)\n",
    "\n",
    "print(f\"Total videos {len(videols) = }\")\n",
    "\n",
    "videopath = pd.DataFrame({\n",
    "    \"videopath\": videols,\n",
    "    \"video_name\": [x.split(\"\\\\\")[-1] for x in videols],\n",
    "    \"video_location\": [x.split(\"\\\\\")[-2] for x in videols],\n",
    "})\n",
    "videopath[\"video_location\"].unique()\n",
    "\n",
    "video_location = [\n",
    "    'bryant_park',\n",
    "    'Chestnut Street videos (NEW)',\n",
    "    'Downtown Crossing videos (NEW)',\n",
    "    'Met Steps videos (NEW)'\n",
    "       ]\n",
    "for i, path in enumerate(videopath.videopath.values):\n",
    "    for loc in video_location:\n",
    "        if loc in path:\n",
    "            videopath.loc[i, \"video_location\"] = loc\n",
    "            \n",
    "videopath = videopath[videopath[\"video_location\"].isin(video_location)]\n",
    "print(f\"Total videos {videopath.shape[0] = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d27a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the video path\n",
    "# videopath['video_indicator'] = \"new_video\"\n",
    "# videopath.to_csv(\"../_data/00_raw/_video_meta/video_path.csv\", \n",
    "#                  index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "249bfdd7",
   "metadata": {},
   "source": [
    "# 2. Pick the ones ready to generate sample frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff17ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_sample = {\n",
    "    'bryant_park':[\"20081008-072238b01.avi\",\"20081008-072238b18.avi\",\"20081008-141944b01.avi\"],\n",
    "    'Chestnut Street videos (NEW)':[\"20100519-083343b04.avi\"],\n",
    "    'Downtown Crossing videos (NEW)':[\"20100521-074701b06.avi\",\"20100521-115755b02.avi\"],\n",
    "    'Met Steps videos (NEW)':[\"20100612-120118b01.avi\",\"20100612-082221b01.avi\",\"20100612-082221b02.avi\",\"20100612-082221b03.avi\"]\n",
    "}\n",
    "\n",
    "allvideos = []\n",
    "for v in video_sample.values():\n",
    "    allvideos.extend(v)\n",
    "allvideos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a977b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the videopath again to retrieve starting and end time\n",
    "videopath = pd.read_csv(\"../../_data/00_raw/_video_meta/video_path_0509.csv\")\n",
    "videopath['video_id'] = videopath['video_name'].apply(lambda x: x.split(\".\")[0])\n",
    "# Generate sample frames from the list of videos\n",
    "videopath['videopath'] = videopath['videopath'].apply(lambda x: x.replace(\"../\", \"../../\"))\n",
    "videosel = videopath[videopath[\"video_name\"].isin(allvideos)].reset_index(drop = True)\n",
    "# videosel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41368659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the video to get their fps and frame count\n",
    "from tqdm import tqdm\n",
    "def getbasics(file_path):\n",
    "    video = cv2.VideoCapture(file_path)\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    # print('frames per second =',fps)\n",
    "    size = (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    \n",
    "    length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    # print('frames size =',size)\n",
    "    # video.release()\n",
    "    return video, fps, size, length\n",
    "\n",
    "for i, path in enumerate(videosel.videopath.values):\n",
    "    video, fps, size, length = getbasics(path)\n",
    "    videosel.loc[i, \"fps\"] = fps\n",
    "    videosel.loc[i, \"w\"] = size[0]\n",
    "    videosel.loc[i, \"h\"] = size[1]\n",
    "    videosel.loc[i, \"length\"] = length\n",
    "    \n",
    "    name = videosel.loc[i, \"video_name\"].split(\".\")[0]\n",
    "    # set the video to the first frame and export a sample image\n",
    "    # this is a generic selection. After split all video to scenes, reselect the first frame dynamically\n",
    "    second_start = 55\n",
    "    minute_start = 1\n",
    "    first_frame = int(fps*(minute_start*60 + second_start))\n",
    "    video.set(cv2.CAP_PROP_POS_FRAMES, first_frame)\n",
    "    success = True\n",
    "    while success:     \n",
    "        success, image = video.read()\n",
    "        try:\n",
    "            cv2.imwrite(os.path.join(sample_frame_folder, f\"{name}_{first_frame}.jpg\"), image)\n",
    "            # save frame as JPEG file \n",
    "            break\n",
    "        except:\n",
    "            first_frame += 1\n",
    "            print(\"first frame not working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d9d2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# integrate the start and end timestamp\n",
    "videopath = pd.read_csv(\"../../_data/00_raw/_video_meta/video_path_0509.csv\")\n",
    "videopath['video_id'] = videopath['video_name'].apply(lambda x: x.split(\".\")[0])\n",
    "videopath = videopath[~videopath['video_name'].str.contains(\"CORRUPT\")].reset_index(drop = True)\n",
    "videopath['video_group'] = videopath['video_id'].apply(lambda x: x.split(\"b\")[0])\n",
    "videopath['video_section'] = videopath['video_id'].apply(lambda x: int(x.split(\"b\")[1]))\n",
    "# load finished prediction names\n",
    "exportfolder = \"../../_data/03_tracking_result/_current_attr_result\"\n",
    "finished = os.listdir(exportfolder)\n",
    "videopath['finished'] = videopath['video_id'].apply(lambda x: x+\".csv\" in finished)\n",
    "\n",
    "videopath['video_group_started_at'] = pd.to_datetime(videopath['video_group'])\n",
    "\n",
    "videopath['video_length_s'] = videopath['length']/29.97\n",
    "# convert the column to timeDelta\n",
    "videopath['video_length_s'] = videopath['video_length_s'].apply(lambda x: pd.Timedelta(seconds = x))\n",
    "\n",
    "videopath['video_section_started_at'] = videopath['video_group_started_at']+ \\\n",
    "    (videopath['video_section']-1)*videopath['video_length_s']\n",
    "# videopath.to_csv(\"../../_data/00_raw/_video_meta/video_path_0509.csv\", index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3db545e",
   "metadata": {},
   "source": [
    "# Following steps\n",
    "1. use the sample frames to find associated plan in QGIS\n",
    "2. Clean up the attribute prediction results\n",
    "3. Remove the half person (by compute the w, h ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3da387",
   "metadata": {},
   "outputs": [],
   "source": [
    "videopath = pd.read_csv(\"../../_data/00_raw/_video_meta/video_path_0509.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538aaaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predfiles = os.listdir(predictfolder)\n",
    "import glob\n",
    "video_names_done = list(set([x.split(\"_\")[0] for x in predfiles]))\n",
    "print(f\"finished {len(video_names_done) = }\")\n",
    "\n",
    "# check to make sure that all videos are corrected\n",
    "remain = videopath[~videopath[\"video_id\"].isin(video_names_done)].reset_index(drop = True)\n",
    "# assert remain.shape[0]==0, \"there are videos not processed yet\"\n",
    "print(f\"remain {remain.shape[0] = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221d3ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_mot_human(mot, hu, i):\n",
    "    motdf = pd.DataFrame(mot[i][\"boxes\"], columns = [\"track_id\", \"frame_id\", \"score\",\"x\", \"y\", \"w\", \"h\"])\n",
    "    # motdf[\"frame_id\"] =motdf[\"frame_id\"]+1 \n",
    "    attr = pd.DataFrame(hu[i], columns = [\n",
    "        \"gender\", \n",
    "        \"age\", \n",
    "        \"side\", \n",
    "        \"glasses\",\n",
    "        \"hat\",\n",
    "        \"hold_objects_in_front\",\n",
    "        \"bag\",\n",
    "        \"upper\",\n",
    "        \"lower\",\n",
    "        \"boots\"\n",
    "    ])\n",
    "    df = pd.concat([motdf, attr], axis = 1)\n",
    "    df[\"frame_id\"] = i\n",
    "    return df\n",
    "\n",
    "def load_tracking(video_name):\n",
    "    humanfile = f\"{video_name}_human_attr.pickle\"\n",
    "    motfiles = f\"{video_name}_mot.pickle\"\n",
    "\n",
    "    human_path = os.path.join(predictfolder, humanfile)\n",
    "    mot_path = os.path.join(predictfolder, motfiles)\n",
    "    import pickle\n",
    "    with open(human_path, \"rb\") as the_file:\n",
    "        hu = pickle.load(the_file)\n",
    "    with open(mot_path, \"rb\") as the_file:\n",
    "        mot = pickle.load(the_file)\n",
    "    DF = []\n",
    "    for i in hu.keys():\n",
    "        df = merge_mot_human(mot, hu, i)\n",
    "        DF.append(df)\n",
    "    DF = pd.concat(DF).reset_index(drop = True)\n",
    "    return DF\n",
    "\n",
    "def find_outliers_IQR(df, field):\n",
    "\n",
    "   q1=df[field].quantile(0.15)\n",
    "\n",
    "   q3=df[field].quantile(0.85)\n",
    "\n",
    "   IQR=q3-q1\n",
    "\n",
    "   outliers = df[((df[field]<(q1-1.5*IQR)) | (df[field]>(q3+1.5*IQR)))]\n",
    "\n",
    "   keep = df[((df[field]>=(q1-1.5*IQR)) & (df[field]<=(q3+1.5*IQR)))]\n",
    "\n",
    "   return outliers, keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportfolder = \"../../_data/03_tracking_result/_current_attr_result\"\n",
    "cleaned = os.listdir(exportfolder)\n",
    "remain_videos = [x for x in video_names_done if x+\".csv\" not in cleaned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f4255",
   "metadata": {},
   "outputs": [],
   "source": [
    "remain_videos = ['20100521-115755b04']\n",
    "DF = load_tracking(remain_videos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9366673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the normal w/h ratio\n",
    "DF['ratio'] = DF['w']/DF['h']\n",
    "DF['ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dccd3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers, keep = find_outliers_IQR(DF, \"ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d6d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep['ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946b1501",
   "metadata": {},
   "outputs": [],
   "source": [
    "for video_name in tqdm(remain_videos):\n",
    "    if not video_name.endswith(\".mp4\"):\n",
    "        try:\n",
    "            DF = load_tracking(video_name)\n",
    "            \n",
    "            DF.to_csv(os.path.join(exportfolder, video_name+\".csv\"), index = False)\n",
    "        except:\n",
    "            # print the error message\n",
    "            print(f\"error in {video_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8403daed",
   "metadata": {},
   "source": [
    "# Archive below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d2fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test one video first\n",
    "testvideo = \"20100521-115755b01\"\n",
    "folder = \"../../_data/00_raw/videos_current_highres/Downtown Crossing videos (NEW)/VID2/20100521-115755b01.avi\"\n",
    "scenedetect --input B11_G1_Env24_0001.mp4 detect-adaptive list-scenes save-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249118d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up test file\n",
    "video_folder = \"../_data/00_raw/videos_current_highres\"\n",
    "old_video_folder = \"../_data/00_raw/_mp4/videos_old_highres\"\n",
    "result_folder = \"../_data/03_tracking_result/_current_videos\"\n",
    "files = os.listdir(video_folder)\n",
    "outfolder = \"../_data/05_tracking_result_projected\"\n",
    "\n",
    "if not os.path.exists(outfolder):\n",
    "    os.makedirs(outfolder)\n",
    "\n",
    "current_video_sel = [\n",
    "    \"bryant_park/20081008-070830b01.avi\",\n",
    "    \"bryant_park/20081008-141944b09.avi\",\n",
    "    \"Chestnut Street videos (NEW)/20100519-083343b01.avi\",\n",
    "    \"Downtown Crossing videos (NEW)/VID1/\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1ae555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image size, fps, and save a sample frame\n",
    "def get_sample_from_folder(vfolder, minute_start=2, second_start=10):\n",
    "    files = os.listdir(vfolder)\n",
    "    for sample_video in tqdm(files):\n",
    "        videoname = sample_video[:-4]\n",
    "        video = cv2.VideoCapture(os.path.join(vfolder, sample_video))\n",
    "\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        print(\"FPS of video \", videoname, \": \", fps)\n",
    "        size = (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "        print(\"Size of video \", videoname, \": \", size)\n",
    "        first_frame = int(fps*(minute_start*60 + second_start))\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, first_frame)\n",
    "        # save a sample frame for image pairing\n",
    "        sample_frame_folder = \"../_data/02_siteplan/sample_frames\"\n",
    "        ret, frame = video.read()\n",
    "        cv2.imwrite(os.path.join(sample_frame_folder, f\"{videoname}.jpg\"), frame)\n",
    "\n",
    "        video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7a4817-fa59-4a89-9192-c3a0003fe69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sample_from_folder(old_video_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449035d9-43e2-4a7d-b96a-d3f0fdd2b1f6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "videoname = files[0][:-4]\n",
    "predpath = os.path.join(result_folder, f'{videoname}.txt')\n",
    "trace = pd.read_csv(predpath,\n",
    "                   sep = ',',\n",
    "                header = None)\n",
    "\n",
    "# trace.columns = [\"frame_id\", \"track_id\", \"bbox0\", \"bbox1\", \"bbox2\", \"bbox3\",\"6\",\"7\",\"8\",\"9\"]\n",
    "trace.columns = [\"frame_id\",\"track_id\",\"bbox0\",\"bbox1\",\"bbox2\",\"bbox3\",\"score\",\"7\",\"8\",\"9\"]\n",
    "trace[\"bbox0\"] = 720 - trace[\"bbox0\"]\n",
    "# trace = trace[trace['track_id'].isin(sel)]\n",
    "trace['loc_x'] = (trace['bbox0'] + trace['bbox0'] + trace['bbox2'])/2\n",
    "trace['loc_y'] = (trace['bbox1'] + trace['bbox3'])\n",
    "\n",
    "trace['bbox0'] = trace['bbox0'].astype(int)\n",
    "trace['bbox1'] = trace['bbox1'].astype(int)\n",
    "trace['bbox2'] = trace['bbox2'].astype(int)\n",
    "trace['bbox3'] = trace['bbox3'].astype(int)\n",
    "trace['frame_id'] = trace['frame_id'].astype(int)\n",
    "\n",
    "# transform the location to image x, y\n",
    "trace['y1'] = trace['bbox0']\n",
    "trace['y2'] = trace['bbox0']+trace['bbox2']\n",
    "\n",
    "trace['x1'] = trace['bbox1']\n",
    "trace['x2'] = trace['bbox1']+trace['bbox3']\n",
    "trace['point'] = trace.apply(lambda row: (int((row['y1']+row['y2'])/2), \n",
    "                                                     int((row['x1']+row['x2'])/2)), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e477d18-18a5-472f-9caa-a7b51381f739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from 10 second to go, set up original video reading process\n",
    "# minutes = 7\n",
    "# seconds = 50\n",
    "# first_frame = int(fps*(minutes*60 + seconds))\n",
    "# last_frame = int(fps*(10*60)+0)\n",
    "# print('frame id =',first_frame)\n",
    "\n",
    "minutes = 13\n",
    "seconds = 26\n",
    "first_frame = int(fps*(minutes*60 + seconds))\n",
    "last_frame = int(fps*(15*60)+21)\n",
    "video = cv2.VideoCapture(os.path.join(folder, file_name))\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, first_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df1d29-af3f-4e1d-8db4-3511f9ea1562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_out.release()\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "video_out = cv2.VideoWriter(outfolder + f\"/{videoname}_{first_frame}_highres.mp4\", fourcc, fps, size)\n",
    "\n",
    "tracks = trace['track_id'].unique()\n",
    "colorls = [tuple(random.choices(range(i%255,255), k = 3)) for i in range(len(tracks))]\n",
    "colorset = dict(zip(tracks, colorls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eda6045-1785-4c1e-9f8c-1162f53e5ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sample v\n",
    "# video_out.release()\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "# video_out = cv2.VideoWriter(outfolder + f\"/{videoname}_{first_frame}_sample.mp4\", fourcc, fps, size)\n",
    "# ret = True\n",
    "# while ret and frame_id<=last_frame:\n",
    "#     ret, frame = video.read()\n",
    "#     frame_id = frame_id+1\n",
    "#     video_out.write(frame)\n",
    "# video_out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae08e18-1dec-4bfc-90e7-926fcc296b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = True\n",
    "import numpy as np\n",
    "frame_id = first_frame\n",
    "while ret and frame_id<=last_frame:\n",
    "    ret, frame = video.read()\n",
    "    frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
    "    data = trace[trace['frame_id']==frame_id].reset_index(drop = True)\n",
    "    for j, tr in enumerate(data['track_id'].values):\n",
    "        cv2.rectangle(frame, \n",
    "                          (data.at[j,'bbox0'], \n",
    "                           data.at[j,'bbox1']), \n",
    "                          (data.at[j,'bbox0']+data.at[j,'bbox2'], \n",
    "                           data.at[j,'bbox1']+data.at[j,'bbox3']), \n",
    "                              colorset[tr], 1)\n",
    "        cv2.putText(\n",
    "                    frame, \n",
    "                    str(tr),\n",
    "                    (data.at[j,'bbox0'], data.at[j,'bbox1']-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, colorset[tr],\n",
    "                    1,\n",
    "                    lineType=cv2.LINE_AA\n",
    "                    )\n",
    "        # Draw Tracks\n",
    "#         tracksline = trace[(trace['track_id']==tr)&(trace['frame_id']<=frame_id)].reset_index(drop = True)\n",
    "#         tracksline.set_index('frame_id', inplace = True)\n",
    "#         start = max(frame_id-100, 0)\n",
    "#         for t in range(start, frame_id):\n",
    "            \n",
    "#             try:\n",
    "#             #if tracksline.at[t,'point'] is None or tracksline.at[t-1,'point'] is None: continue\n",
    "#             #else:\n",
    "#                 cv2.line(frame, tracksline.at[t,'point'], tracksline.at[t-1,'point'], colorset[tr], \n",
    "#                      thickness = int(np.sqrt(49 / float((t-start) + 1)) * 2))\n",
    "#             except:\n",
    "#                 continue\n",
    "    frame_id = frame_id+1\n",
    "    video_out.write(frame)\n",
    "video_out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d19ddf-4b04-4739-9831-f47d4d28a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1800\n",
    "int(np.sqrt(49 / float((t-start) + 1)) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d6ca09-ce98-4a1c-b36d-a63aeb2febd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 1850\n",
    "int(np.sqrt(49 / float((t-start) + 1)) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c3fadb-0656-4b1a-b36c-f892719ee488",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(np.sqrt(100 / float((t-start) + 1)) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d40ebc0-6d0d-4831-a13e-bca44765ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = frame_id - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58176e56-d6ff-4af1-9b94-3087836bfc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.5, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20779afc-4afc-4165-8a8b-eaf0d49eb9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535ac1df-8bef-4b51-910e-0b0bf5b42b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(np.sqrt(49 / float(t + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c34325-91bc-4fc7-ad47-d915d32c4177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0fdb9f36a2fa6c0d80c32614b079baf171674cda7a504cb8efc605d7162d1d77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
