{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "# from osgeo import gdal\n",
    "# from osgeo import osr\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "\n",
    "def imshow(image, show_axes = False, quiet = False):\n",
    "    if len(image.shape) == 3:\n",
    "      # Height, width, channels\n",
    "      # Assume BGR, do a conversion since \n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "      # Height, width - must be grayscale\n",
    "      # convert to RGB, since matplotlib will plot in a weird colormap (instead of black = 0, white = 1)\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    # Draw the image\n",
    "    plt.imshow(image)\n",
    "    if not show_axes:\n",
    "        # We'll also disable drawing the axes and tick marks in the plot, since it's actually an image\n",
    "        plt.axis('off')\n",
    "    if not quiet:\n",
    "        # Make sure it outputs\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal:\n",
    "This note book use detected (tracked) person with individual attributes to aggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proj_matrix(ref):\n",
    "    '''\n",
    "\n",
    "    pts_src and pts_dst are numpy arrays of points\n",
    "\n",
    "    in source and destination images. We need at least\n",
    "\n",
    "    corresponding points.\n",
    "\n",
    "    '''\n",
    "    try:\n",
    "        pts_src = np.array([(x,y) for x,y in zip(ref['sourceX'], -1*ref['sourceY'])])\n",
    "    except:\n",
    "        pts_src = np.array([(x,y) for x,y in zip(ref['pixelX'], -1*ref['pixelY'])])\n",
    "\n",
    "    pts_dst  = np.array([(x,y) for x,y in zip(ref['mapX'], ref['mapY'])])\n",
    "\n",
    "    h, status = cv2.findHomography(pts_src, pts_dst)\n",
    "\n",
    "    '''\n",
    "    The calculated homography can be used to warp\n",
    "\n",
    "    the source image to destination. Size is the\n",
    "\n",
    "    size (width,height) of im_dst\n",
    "    '''\n",
    "    return h\n",
    "\n",
    "def projectPlan(df, h, x, y):\n",
    "    pts = df[[x, y]].values\n",
    "    ## (n, 1, 2)\n",
    "    pts1 = pts.reshape(-1,1,2).astype(np.float32)\n",
    "    dst1 = cv2.perspectiveTransform(pts1, h)\n",
    "    return dst1\n",
    "\n",
    "\n",
    "def pixel2coord(col, row, ds):\n",
    "    # 3. transform to 2326 geolocation\n",
    "    c, a, b, f, d, e = ds.GetGeoTransform()\n",
    "    \"\"\"Returns global coordinates to pixel center using base-0 raster index\"\"\"\n",
    "    xp = a * col + b * row + a * 0.5 + b * 0.5 + c\n",
    "    yp = d * col + e * row + d * 0.5 + e * 0.5 + f\n",
    "    return(xp, yp)\n",
    "\n",
    "\n",
    "# bbox0, bbox1, bbox2, bbox3 : x1, y1, w, h\n",
    "# Replace this part for other data\n",
    "# Trace\n",
    "\n",
    "# check gender distribution within one track_id\n",
    "# set attribute list\n",
    "# def get_attr(trace):\n",
    "#     attribute_ls = ['gender', 'age', 'side', 'glasses', 'hat', 'hold_objects_in_front',\n",
    "#         'bag', 'upper', 'lower', 'boots']\n",
    "#     # for each track_id only keep one major attribute\n",
    "#     for attr in attribute_ls:\n",
    "#         trace[attr] = trace.groupby(\"track_id\")[attr].transform(lambda x: x.mode()[0])\n",
    "#     trace[trace[\"track_id\"] == 1].groupby([\"gender\"]).size()\n",
    "\n",
    "#     attr_df = trace.drop_duplicates(\"track_id\")[attribute_ls+[\"track_id\"]]\n",
    "#     return attr_df\n",
    "\n",
    "def getclean(trace, h, epsg, videoname):\n",
    "\n",
    "    trace['loc_x'] = (trace['bbox0'] + trace['bbox0'] + trace['bbox2'])/2\n",
    "    trace['loc_y'] = (trace['bbox1'] + trace['bbox3'])\n",
    "    \n",
    "    trs2 = projectPlan(trace, h, 'loc_x', 'loc_y')\n",
    "    trace[f'x_{epsg}'] = trs2[:,:,0]\n",
    "    trace[f'y_{epsg}'] = trs2[:,:,1] \n",
    "    \n",
    "    trace['video_id'] = videoname\n",
    "\n",
    "        # smoothe the x, y for every 30 frames\n",
    "    attribute_ls = ['gender', \n",
    "                    'age', \n",
    "                    'side', \n",
    "                    'glasses', \n",
    "                    'hat', \n",
    "                    'hold_objects_in_front',\n",
    "                    'bag', \n",
    "                    'upper', \n",
    "                    'lower', \n",
    "                    'boots']\n",
    "    \n",
    "    cols = ['video_id',\n",
    "        'frame_id',\n",
    "                  'track_id','loc_x', 'loc_y',\n",
    "                     f'x_{epsg}', f'y_{epsg}', # reference geo in HK\n",
    "                     'category_id',\n",
    "                     \"score\"\n",
    "                  ]\n",
    "    cols_keep = [x for x in trace.columns if x in cols+attribute_ls]\n",
    "    return trace[cols_keep]\n",
    "            \n",
    "\n",
    "def getgdf(traceDF, epsg, tail = True, length = 3):\n",
    "    \"\"\"length: refers to the second of lagging tail we want to see\"\"\"\n",
    "    # smoothe the x, y for every 30 frames\n",
    "    traceDF['moving_x'] = traceDF.groupby('track_id')[f'x_{epsg}'].transform(lambda x: x.rolling(5, 1).mean())\n",
    "    traceDF['moving_y'] = traceDF.groupby('track_id')[f'y_{epsg}'].transform(lambda x: x.rolling(5, 1).mean())\n",
    "\n",
    "    traceGDF = gpd.GeoDataFrame(traceDF, geometry = [Point(x,y) for x,y in zip(traceDF[f'x_{epsg}'],\n",
    "                                                                               traceDF[f'y_{epsg}'])])\n",
    "    traceGDF.crs = f\"EPSG:{epsg}\"\n",
    "    traceGDF = traceGDF.to_crs('EPSG:4326')\n",
    "    traceGDF['lat'] = traceGDF['geometry'].y\n",
    "    traceGDF['lon'] = traceGDF['geometry'].x\n",
    "    \n",
    "    traceGDF['lat_moving'] = traceGDF.groupby('track_id')['lat'].transform(lambda x: x.rolling(5, 1).mean())\n",
    "    traceGDF['lon_moving'] = traceGDF.groupby('track_id')['lon'].transform(lambda x: x.rolling(5, 1).mean())\n",
    "    return traceGDF\n",
    "\n",
    "# drop the outlier automatically\n",
    "def find_outliers_IQR(df, field, low = 0.25, high = 0.75):\n",
    "\n",
    "   q1=df[field].quantile(low)\n",
    "\n",
    "   q3=df[field].quantile(high)\n",
    "\n",
    "   IQR=q3-q1\n",
    "\n",
    "   outliers = df[((df[field]<(q1-1.5*IQR)) | (df[field]>(q3+1.5*IQR)))]\n",
    "\n",
    "   keep = df[((df[field]>=(q1-1.5*IQR)) & (df[field]<=(q3+1.5*IQR)))].reset_index(drop = True)\n",
    "\n",
    "   return outliers, keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proj_video(videoname, ref):\n",
    "    \"\"\"For new videos, we extract the detection results from tracks\"\"\"\n",
    "    result_folder = \"../../_data/03_tracking_result/_current_attr_result\"\n",
    "    predpath = os.path.join(result_folder, f'{videoname}.csv')\n",
    "    trace = pd.read_csv(predpath)\n",
    "    trace['ratio'] = trace['w']/trace['h']\n",
    "    _, trace = find_outliers_IQR(trace, 'ratio', 0.15, 0.85)\n",
    "    trace.rename(columns = {\"x\":\"bbox0\", \"y\":\"bbox1\", \"w\":\"bbox2\", \"h\":\"bbox3\"}, inplace = True)\n",
    "    h = get_proj_matrix(ref)\n",
    "# # Set up projection for New York State Plane\n",
    "# set up to match the projection of the reference data\n",
    "    # epsg = 3857  #2263\n",
    "    epsg = videopath_sel[videopath_sel['video_id']==videoname]['ref_epsg'].values[0]\n",
    "    traceDF = getclean(trace, h, epsg, videoname)\n",
    "    traceGDF = getgdf(traceDF, epsg)\n",
    "    \n",
    "    attr_df = get_attr(traceDF)\n",
    "\n",
    "    # drop outliers\n",
    "    _, traceGDF_keep = find_outliers_IQR(traceGDF, \"moving_x\")\n",
    "    \n",
    "    traceGDF = traceGDF_keep.drop([\"gender\",\"age\"], axis = 1).merge(attr_df[[\"track_id\", \"gender\", \"age\"]], \n",
    "                                                                    on = \"track_id\", how = \"left\")\n",
    "    \n",
    "    return traceGDF\n",
    "\n",
    "def getbasics(file_path):\n",
    "    video = cv2.VideoCapture(file_path)\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    print('frames per second =',fps)\n",
    "    size = (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    print('frames size =',size)\n",
    "    # video.release()\n",
    "    return video, fps, size\n",
    "\n",
    "# read in the points\n",
    "def get_ref(ref_path):\n",
    "    # with open(ref_folder + ref_video + f\"_3446_modified.tif.points\", \"r\") as f:\n",
    "    with open(os.path.join(ref_folder, ref_path), \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.strip().split(\",\") for line in lines]\n",
    "    # convert to dataframe\n",
    "    ref = pd.DataFrame(lines[1:], columns = lines[0])\n",
    "    # convert to float\n",
    "    ref = ref.astype(float)\n",
    "    return ref\n",
    "\n",
    "\n",
    "def get_all_info(videoname, useimage = True):\n",
    "    # frame_folder = \"../_data/02_siteplan/sample_frames\"\n",
    "    # tiff_folder = \"../_data/02_siteplan/geo_tiff\"\n",
    "    # ref_folder = \"../_data/02_siteplan/gcp_pt/\"\n",
    "\n",
    "    # ref = pd.read_csv(os.path.join(ref_folder, f'{videoname}_reference.txt'), sep = \",\")\n",
    "    ref_path = videopath_sel[videopath_sel['video_id']==videoname]['ref_path'].values[0]\n",
    "    ref = get_ref(ref_path)\n",
    "    # targetimg  = cv2.cvtColor(cv2.imread(os.path.join(tiff_folder, f'{videoname}_modified.tif')), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #===================== PLOT the reference points =====================\n",
    "    # originimg  = cv2.cvtColor(cv2.imread(os.path.join(frame_folder, f'{videoname}_{frame_start}.jpg')), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # fig, ax = plt.subplots(figsize = (10,10))\n",
    "    # plt.imshow(originimg)\n",
    "    # try:\n",
    "    #     plt.scatter(ref['pixelX'], -1*ref['pixelY'], color = 'red')\n",
    "    # except:\n",
    "    #     plt.scatter(ref['sourceX'], -1*ref['sourceY'], color = 'red')\n",
    "    # if useimage:\n",
    "    #     traceGDF_keep = get_proj_img(videoname, ref)\n",
    "    # else:\n",
    "    traceGDF_keep = get_proj_video(videoname, ref)\n",
    "    if \"category_id\" in traceGDF_keep.columns:\n",
    "        traceGDF_people = traceGDF_keep[(traceGDF_keep[\"category_id\"] == 0)&(traceGDF_keep[\"score\"]>0.1)].reset_index(drop = True)\n",
    "        return traceGDF_people\n",
    "    else:\n",
    "        return traceGDF_keep\n",
    "    \n",
    "def get_frame_num(time_str, fps = 29.97002997002997):\n",
    "    try:\n",
    "        time = time_str.split(\" \")[0][3:].split(\":\")\n",
    "        minute = int(time[0])\n",
    "        second = int(time[1])\n",
    "        frame = minute*60*fps + second*fps\n",
    "        return int(frame)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "outputfolder = \"../../_data/05_tracking_result_projected/step0_attr_prj\"\n",
    "frame_folder = \"../../_data/02_siteplan/sample_frames/current_sample\"\n",
    "tiff_folder = \"../../_data/02_siteplan/geo_tiff\"\n",
    "ref_folder = \"../../_data/02_siteplan/gcp_pt/\"\n",
    "frames = os.listdir(frame_folder)\n",
    "refs = os.listdir(ref_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videopath = pd.read_csv(\"../../_data/00_raw/_video_meta/video_path_0509.csv\")\n",
    "\n",
    "# videopath_sel = videopath[videopath['scene'].isin([2,3])]\n",
    "videopath_sel = videopath[~videopath['ref_path'].isna()].reset_index(drop = True)\n",
    "videopath_sel['first_effective_time'].unique()\n",
    "videopath_sel['first_effective_time'] = videopath_sel['first_effective_time'].fillna(\"12:00:00 AM\")\n",
    "videopath_sel['frame_start'] = videopath_sel['first_effective_time'].apply(lambda x: get_frame_num(x))\n",
    "\n",
    "# videopath_sel['last_effective_time'] = videopath_sel['last_effective_time'].fillna(\"12:00:00 AM\")\n",
    "videopath_sel['frame_end'] = videopath_sel['last_effective_time'].apply(lambda x: get_frame_num(x))\n",
    "videopath_sel['frame_end'] = videopath_sel['frame_end'].fillna(videopath_sel['length'])\n",
    "videopath_sel['ref_epsg'] = videopath_sel['ref_epsg'].astype(int)\n",
    "\n",
    "videopath_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videopath[(videopath['finished']==True)&(videopath['ref_path'].isna())].groupby(\"video_location\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all projected csv\n",
    "projected = glob.glob(outputfolder+\"/*/*_projected.csv\")\n",
    "projected_names = [x.split(\"\\\\\")[-1].split(\"_\")[0] for x in projected]\n",
    "# now_processing = videopath_sel[~videopath_sel['video_id'].isin(projected_names)].reset_index(drop = True)\n",
    "now_processing = videopath_sel.copy()\n",
    "now_processing = now_processing[now_processing['video_location']!='Met Steps videos (NEW)'].reset_index(drop = True)\n",
    "now_processingls = now_processing['video_id'].unique().tolist()\n",
    "len(now_processingls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for videoname in tqdm(now_processingls):\n",
    "    print(videoname)\n",
    "    try:\n",
    "        traceGDF_people = get_all_info(videoname,  \n",
    "                                    useimage = False)\n",
    "        file_path = videopath[videopath['video_id'] == videoname]['videopath'].values[0]\n",
    "        # video, fps, size = getbasics(file_path)\n",
    "        fps = videopath[videopath['video_id'] == videoname]['fps'].values[0]\n",
    "        \n",
    "        # only keep the frame_id after the first desired frame\n",
    "        first_frame_sel = videopath_sel[videopath_sel['video_id']== videoname]['frame_start'].values[0]\n",
    "        last_frame_sel = videopath_sel[videopath_sel['video_id']== videoname]['frame_end'].values[0]\n",
    "        traceGDF_people = traceGDF_people[(traceGDF_people['frame_id']<=last_frame_sel)&(traceGDF_people['frame_id']>=first_frame_sel)].reset_index(drop = True)\n",
    "        \n",
    "        traceGDF_people[\"second\"] = traceGDF_people[\"frame_id\"]//fps\n",
    "        # sample = traceGDF_people[traceGDF_people[\"second\"]<20] # pick 20 seconds sample\n",
    "        loc_name = videopath[videopath['video_id'] == videoname]['video_location'].values[0]\n",
    "        destfolder = os.path.join(outputfolder, loc_name)\n",
    "        if not os.path.exists(destfolder):\n",
    "            os.makedirs(destfolder)\n",
    "        traceGDF_people.drop(\"geometry\", axis = 1).to_csv(os.path.join(destfolder, \n",
    "                                                                       f\"{videoname}_projected.csv\"), index = False)\n",
    "    except:\n",
    "        print(f\"error in {videoname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# videoname = now_processingls[0]\n",
    "# loc_name = videopath[videopath['video_id'] == videoname]['video_location'].values[0]\n",
    "# destfolder = os.path.join(outputfolder, loc_name)\n",
    "\n",
    "# traceGDF_people = pd.read_csv(os.path.join(destfolder, f\"{videoname}_projected.csv\"))\n",
    "# traceGDF_people.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test draw image to see the detection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# historical videofolder:\n",
    "# file_path = f\"../_data/00_raw/_mp4/videos_old_highres/{videoname}.mp4\"\n",
    "# current videofolder:\n",
    "# file_path = f\"../_data/00_raw/videos_current_highres/bryant_park/{videoname}.avi\"\n",
    "# videoname = \"20100519-083343b11\"\n",
    "videopath = pd.read_csv(\"../../_data/00_raw/_video_meta/video_path.csv\")\n",
    "videopath['video_id'] = videopath['video_name'].apply(lambda x: x.split(\".\")[0])\n",
    "file_path = videopath[videopath['video_id'] == videoname]['videopath'].values[0]\n",
    "\n",
    "loc = videopath[videopath['video_id'] == videoname]['video_location'].values[0]\n",
    "video, fps, size = getbasics(file_path)\n",
    "frame_id = 350\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, frame_id)\n",
    "ret, frame = video.read()\n",
    "# plot the frame\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "fig = plt.subplots(figsize = (10,10))\n",
    "plt.imshow(frame)\n",
    "\n",
    "# load traceGDF_people for this video\n",
    "destfolder = os.path.join(outputfolder, loc)\n",
    "filepath = os.path.join(destfolder, f\"{videoname}_projected.csv\")\n",
    "traceGDF_people = pd.read_csv(filepath)\n",
    "temp = traceGDF_people[traceGDF_people[\"frame_id\"] == frame_id]\n",
    "plt.scatter(\n",
    "    temp[\"loc_x\"], \n",
    "    temp[\"loc_y\"], color = 'red')\n",
    "\n",
    "# export the x,y coordinates to csv of this one frame\n",
    "# temp[[\"geometry\",\"track_id\"]].to_file(f\"../_data/05_demo/2023-04-30/{videoname}_frame_{frame_id}.geojson\", \n",
    "# driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = gpd.GeoDataFrame(temp, geometry = gpd.points_from_xy(temp[\"lon\"], temp[\"lat\"]))\n",
    "temp.crs = \"EPSG:4326\"\n",
    "temp[[\"geometry\",\"track_id\"]].to_file(f\"../_data/05_demo/2023-04-30/{videoname}_frame_{frame_id}.geojson\", \n",
    "driver = \"GeoJSON\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualize the track examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videopath = pd.read_csv(\"../_data/00_raw/_video_meta/video_path.csv\")\n",
    "outputfolder = \"../_data/05_tracking_result_projected/step0_attr_prj\"\n",
    "now_processing = videopath_sel[videopath_sel[\"finished\"]==True].reset_index(drop = True)\n",
    "# select one video for trace visualization\n",
    "videoname = now_processing['video_id'][1]\n",
    "destfolder = os.path.join(outputfolder, \"bryant_park\")\n",
    "trace = pd.read_csv(os.path.join(destfolder, f\"{videoname}_projected.csv\"))\n",
    "traceGDF = gpd.GeoDataFrame(trace, geometry=gpd.points_from_xy(trace.lon, trace.lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsg = 3857\n",
    "\n",
    "# plot a trace sample\n",
    "temp = traceGDF[traceGDF[\"frame_id\"]<1000]\n",
    "# construct lines\n",
    "tracesum = temp.groupby(\"track_id\").size().reset_index().rename(columns = {0:\"count\"})\n",
    "trackidls = tracesum[tracesum[\"count\"]>10][\"track_id\"].unique()\n",
    "geo_df2 = temp[temp[\"track_id\"].isin(trackidls)].sort_values(\"frame_id\").reset_index(drop = True)\\\n",
    ".groupby(['track_id',\"gender\", \"age\"])['geometry'].apply(lambda x: LineString(x.tolist())).reset_index()\n",
    "\n",
    "geo_df2.crs = \"EPSG:4326\"\n",
    "geo_df2 = geo_df2.to_crs(f\"EPSG:{epsg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert and print pass\n",
    "assert geo_df2.crs == f\"EPSG:{epsg}\", \"crs is not correct\"\n",
    "\n",
    "geo_df2.plot(column = \"gender\", figsize = (10,10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export at h3 level for occupation rate estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 29\n",
    "traceGDF[\"second_from_start\"] = traceGDF[\"frame_id\"]/fps\n",
    "\n",
    "traceGDF[\"minute\"] = traceGDF[\"second_from_start\"]//60\n",
    "traceGDF[\"hour\"] = traceGDF[\"second_from_start\"]//3600\n",
    "traceGDF[\"second\"] = traceGDF[\"second_from_start\"]- traceGDF[\"hour\"]*3600 - traceGDF[\"minute\"]*60\n",
    "traceGDF[\"timestamp\"] = \"2008-10-08\"+\" \" + traceGDF[\"hour\"].astype(str) + \":\"+traceGDF[\"minute\"].astype(str).str.zfill(2)\\\n",
    "    +\":\"+traceGDF[\"second\"].astype(str)\n",
    "traceGDF[\"timestamp\"] = pd.to_datetime(traceGDF[\"timestamp\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert all dectection to hexagon 15 for aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traceGDF.to_file(os.path.join(clipfolder, f\"{videoname[:-4]}_prediction_with_attr.geojson\"), driver = \"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traceGDF = pd.read_csv(r\"D:\\Dropbox (MIT)\\whyte_CV\\_data\\05_tracking_result_projected\\step0_attr_prj\\20081008-141944b03_projected_with_attr.csv\")\n",
    "traceGDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h3 import h3\n",
    "res = 15\n",
    "traceGDF[f\"h3_{res}\"] = traceGDF.apply(lambda row: h3.geo_to_h3(row[\"lat\"], row[\"lon\"], res), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count people per h3 id per minute per gender\n",
    "\n",
    "countpeople_gender = traceGDF.groupby([f\"h3_{res}\",\"gender\"])[\"track_id\"].nunique().reset_index()\\\n",
    "    .pivot(columns = \"gender\", index = [\"h3_15\"], values = \"track_id\").reset_index().fillna(0)\n",
    "countpeople_gender\n",
    "# countpeople_gender.to_csv(os.path.join(outfolder, f\"{videoname}_prediction_aggregation.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countpeople_age = traceGDF.groupby([f\"h3_{res}\",\"age\"])[\"track_id\"].nunique().reset_index()\\\n",
    "    .pivot(columns = \"age\", index = [\"h3_15\"], values = \"track_id\").reset_index().fillna(0)\n",
    "countpeople_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = countpeople_gender.merge(countpeople_age, on = [\"h3_15\"], how = \"outer\")\n",
    "summary[\"total\"] = summary[\"Female\"]+summary[\"Male\"]\n",
    "outfolder = \"../_data/05_tracking_result_projected\"\n",
    "summary.to_csv(os.path.join(outfolder, f\"{videoname}_prediction_aggregation_overall.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = traceGDF_keep.groupby(\"track_id\").size().reset_index()\n",
    "summary[summary[0]>fps].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countpeople = traceGDF_keep.groupby([f\"h3_{res}\"])[\"track_id\"].nunique().reset_index()\n",
    "countpeople.to_csv(os.path.join(clipfolder, f\"{videoname}_prediction_aggregation_all.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "0fdb9f36a2fa6c0d80c32614b079baf171674cda7a504cb8efc605d7162d1d77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
