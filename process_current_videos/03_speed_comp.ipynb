{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h3 import h3\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "from osgeo import osr\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "# seaborn stacked bar plot per frame the stationary and moving people\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "def imshow(image, show_axes = False, quiet = False):\n",
    "    if len(image.shape) == 3:\n",
    "      # Height, width, channels\n",
    "      # Assume BGR, do a conversion since \n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "      # Height, width - must be grayscale\n",
    "      # convert to RGB, since matplotlib will plot in a weird colormap (instead of black = 0, white = 1)\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    # Draw the image\n",
    "    plt.imshow(image)\n",
    "    if not show_axes:\n",
    "        # We'll also disable drawing the axes and tick marks in the plot, since it's actually an image\n",
    "        plt.axis('off')\n",
    "    if not quiet:\n",
    "        # Make sure it outputs\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: Calculate speed for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "outputfolder = \"../../_data/05_tracking_result_projected/step0_attr_prj\"\n",
    "outputfolder_2 = \"../../_data/05_tracking_result_projected/step0_no_attr_prj\"\n",
    "\n",
    "# outputfolder = \"../../_data/05_tracking_result_projected/step0_attr_prj_speed_05\"\n",
    "\n",
    "\n",
    "def get_frame_num(time_str, fps = 29.97002997002997):\n",
    "    try:\n",
    "        time = time_str.split(\" \")[0][3:].split(\":\")\n",
    "        minute = int(time[0])\n",
    "        second = int(time[1])\n",
    "        frame = minute*60*fps + second*fps\n",
    "        return int(frame)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate unique number of people appeared for each frame on a time series\n",
    "# load a sample video first\n",
    "def load_video(videoname, outputfolder):\n",
    "\n",
    "    loc_name = videopath_sel[videopath_sel['video_id']==videoname]['video_location'].values[0]\n",
    "    video_start_frame = videopath_sel[videopath_sel['video_id']==videoname]['frame_start'].values[0]\n",
    "    video_start_at = videopath_sel[videopath_sel['video_id']==videoname]['video_section_started_at'].values[0]\n",
    "    video_group = videopath_sel[videopath_sel['video_id']==videoname]['video_group'].values[0]\n",
    "\n",
    "    destfolder = os.path.join(outputfolder, loc_name)\n",
    "    traceGDF = pd.read_csv(os.path.join(destfolder, f\"{videoname}_projected.csv\"))\n",
    "    traceGDF = traceGDF[traceGDF['frame_id']>video_start_frame].reset_index(drop = True)\n",
    "    traceGDF['timestamp'] = video_start_at + traceGDF['frame_id'].apply(lambda x: pd.Timedelta(seconds = x/29.97))\n",
    "    traceGDF['video_group'] = video_group\n",
    "    traceGDF['videoname'] = videoname\n",
    "    \n",
    "    \n",
    "    return traceGDF\n",
    "\n",
    "# drop the outlier speed\n",
    "def find_outliers_IQR(df, field):\n",
    "\n",
    "   q1=df[field].quantile(0.25)\n",
    "\n",
    "   q3=df[field].quantile(0.75)\n",
    "\n",
    "   IQR=q3-q1\n",
    "\n",
    "   outliers = df[((df[field]<(q1-1.5*IQR)) | (df[field]>(q3+1.5*IQR)))]\n",
    "\n",
    "   keep = df[((df[field]>=(q1-1.5*IQR)) & (df[field]<=(q3+1.5*IQR)))]\n",
    "\n",
    "   return outliers, keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use one video as an example\n",
    "# consider the fact that same person can stop and move. So we calculate the 5 second average for each person\n",
    "def get_speed_vector(keepGDF, n = 2, fps = 29.97, globalcrs = \"EPSG:3857\"):\n",
    "    \"\"\"This function calculate the speed vector for each track\"\"\"\n",
    "    keepGDF = gpd.GeoDataFrame(keepGDF, geometry = [Point(x,y) for x,y in zip(keepGDF['lon'], keepGDF['lat'])], crs = f\"EPSG:4326\")\n",
    "    keepGDF = keepGDF.to_crs(globalcrs)\n",
    "    \n",
    "    # calculate individual walking speed at each frame\n",
    "    # step 1: calculate distance between every n seconds\n",
    "    shift_inter = int(n*fps)\n",
    "    keepGDF = keepGDF.sort_values(['track_id','frame_id', \n",
    "                                   ]).reset_index(drop = True)\n",
    "\n",
    "    \n",
    "    keepGDF['dist'] = keepGDF.groupby('track_id')['geometry'].transform(lambda x: x.shift(2).distance(x)).fillna(method='bfill')\n",
    "        \n",
    "    # break the track_id when the move_m_{n}s is too large\n",
    "    threshold = 2.5 # maximum walking speed\n",
    "    distancemax = n*threshold\n",
    "    keepGDF['track_id_backup'] = keepGDF['track_id']\n",
    "    keepGDF['track_id_break'] = np.where(keepGDF['dist']>2, 1, 0)\n",
    "    keepGDF['track_id_update'] = keepGDF['track_id_break'].fillna(0).astype(int)\n",
    "    keepGDF['track_id_update'] = keepGDF.groupby('track_id')['track_id_update'].cumsum()\n",
    "    keepGDF['track_id_combo'] = keepGDF['track_id'].astype(int).astype(str) + \"_\" + keepGDF['track_id_update'].astype(str)\n",
    "    keepGDF['track_id'] = keepGDF['track_id_combo']\n",
    "    \n",
    "    \n",
    "    # recompute the speed from here:\n",
    "    keepGDF[f'move_m_{n}s'] = keepGDF.groupby('track_id')['geometry']\\\n",
    "        .transform(lambda x: x.shift(shift_inter).distance(x))\n",
    "    \n",
    "    keepGDF[f'speed_{n}s'] = keepGDF[f'move_m_{n}s']/n\n",
    "    keepGDF[f'speed_{n}s'] = keepGDF.groupby('track_id')[f'speed_{n}s'].fillna(method = 'bfill')\n",
    "    # calcualte speed_x and speed_y for each person\n",
    "    keepGDF['x_3857'] = keepGDF['geometry'].x\n",
    "    keepGDF['y_3857'] = keepGDF['geometry'].y\n",
    "    keepGDF[f'dist_x_{n}s'] = keepGDF.groupby('track_id')['x_3857'].transform(lambda x: x.shift(shift_inter).fillna(method = 'bfill')-x)\n",
    "    keepGDF[f'dist_y_{n}s'] = keepGDF.groupby('track_id')['y_3857'].transform(lambda x: x.shift(shift_inter).fillna(method = 'bfill')-x)\n",
    "    keepGDF[f'speed_x_{n}s'] = keepGDF[f'dist_x_{n}s']/n\n",
    "    keepGDF[f'speed_y_{n}s'] = keepGDF[f'dist_y_{n}s']/n\n",
    "    return keepGDF\n",
    "\n",
    "def select_thred(traceGDF, i, unit = 'frame_id'):\n",
    "    # traceGDF[unit] = traceGDF['frame_id'].apply(lambda x: int(x/29.97))\n",
    "    summary = traceGDF.groupby([unit,f'stationary_{i+1}'])['track_id'].nunique().reset_index()\\\n",
    "        .pivot(columns = f'stationary_{i+1}', index = unit, values = 'track_id').reset_index().fillna(0)\\\n",
    "            .rename(columns = {0:'moving', 1:'stationary'})\n",
    "    summary_2 = traceGDF.groupby([unit])['track_id'].nunique().reset_index().fillna(0)\n",
    "    summary_all = summary.merge(summary_2, on = unit, how = 'left').rename(columns = {'track_id':'total_pedestrian'})\n",
    "\n",
    "    # summary = summary.set_index(unit)\n",
    "    return summary_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stagingfolder = \"../../_data/05_tracking_result_projected/step1_speed_vector\"\n",
    "stagingfolder = \"../../_data/05_tracking_result_projected/step1_speed_vector_05\"\n",
    "if not os.path.exists(stagingfolder):\n",
    "    os.mkdir(stagingfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videopath = pd.read_csv(\"../../_data/00_raw/_video_meta/video_path_0509.csv\")\n",
    "videopath['video_id'] = videopath['video_name'].apply(lambda x: x.split(\".\")[0])\n",
    "\n",
    "# videopath_sel = videopath[videopath['scene'].isin([2,3])]\n",
    "videopath_sel = videopath[~videopath['ref_path'].isna()].reset_index(drop = True)\n",
    "videopath_sel['first_effective_time'].unique()\n",
    "videopath_sel['first_effective_time'] = videopath_sel['first_effective_time'].fillna(\"12:00:00 AM\")\n",
    "videopath_sel['frame_start'] = videopath_sel['first_effective_time'].apply(lambda x: get_frame_num(x))\n",
    "videopath_sel['frame_end'] = videopath_sel['last_effective_time'].apply(lambda x: get_frame_num(x))\n",
    "videopath_sel['frame_end'] = videopath_sel['frame_end'].fillna(videopath_sel['length'])\n",
    "videopath_sel['ref_epsg'] = videopath_sel['ref_epsg'].astype(int)\n",
    "videopath_sel['video_date'] = videopath_sel['video_group_started_at'].apply(lambda x: x.split(\" \")[0])\n",
    "videopath_sel['video_section_started_at'] = pd.to_datetime(videopath_sel['video_date']+ \" \" +videopath_sel['video_section_started_at'])\n",
    "videols = videopath_sel[videopath_sel['video_location']!='bryant_park']['video_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videols = videopath_sel['video_id'].unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finished = os.listdir(stagingfolder)\n",
    "# finished_name = [x.split(\".\")[0] for x in finished]\n",
    "# remain = [x for x in videols if x not in finished_name]\n",
    "# remain = os.listdir(stagingfolder)\n",
    "remain = os.listdir(outputfolder_2+'/Met Steps videos (NEW)')\n",
    "remain = [x.split('_')[0] for x in remain]\n",
    "len(remain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0.5\n",
    "# fullGDF = []\n",
    "for videoname in tqdm(remain):\n",
    "    # try:\n",
    "    traceGDF = load_video(videoname, outputfolder_2) # change here\n",
    "    \n",
    "    traceGDF = get_speed_vector(traceGDF, n, fps = 29.97, globalcrs = \"EPSG:3857\")\n",
    "    traceGDF['video_location'] = videopath_sel[videopath_sel['video_id']==videoname]['video_location'].values[0]\n",
    "    traceGDF.drop('geometry', axis = 1).to_csv(os.path.join(stagingfolder, f\"{videoname}.csv\"), index = False)\n",
    "        # fullGDF.append(traceGDF)\n",
    "    # except:\n",
    "    #     print(videoname, \": failed\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = traceGDF[traceGDF['track_id_backup']==1].reset_index(drop = True)\n",
    "ax = sample[sample['speed_0.5s']<=2].plot(column = 'track_id', legend = True)\n",
    "# sample[sample['speed_0.5s']>2].plot(color = 'red', ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleupdate = sample.groupby('track_id')['frame_id'].nunique().sort_values().reset_index()\n",
    "sletrack = sampleupdate[sampleupdate['frame_id']>1]['track_id'].unique().tolist()\n",
    "sample = sample[sample['track_id'].isin(sletrack)]\n",
    "ax = sample.plot(column = 'track_id', legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to LinString\n",
    "sampleline = sample.sort_values('frame_id').groupby('track_id').apply(lambda x: LineString(x[['lon', 'lat']].values.tolist()))\\\n",
    "    .reset_index().rename(columns = {0:'geometry'})\n",
    "sampleline = gpd.GeoDataFrame(sampleline, geometry = 'geometry', crs = \"EPSG:4326\")\n",
    "sampleline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_file('test_update.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldstaging = '../../_data/05_tracking_result_projected/step1_speed_vector'\n",
    "files = os.listdir(oldstaging)\n",
    "filenames = [x.split(\".\")[0] for x in files]\n",
    "finished = os.listdir(stagingfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other data beyond the MET\n",
    "n = 0.5\n",
    "# fullGDF = []\n",
    "for videoname in tqdm(filenames):\n",
    "    try:\n",
    "        traceGDF = load_video(videoname, outputfolder) # change here\n",
    "        traceGDF = get_speed_vector(traceGDF, n, fps = 29.97, globalcrs = \"EPSG:3857\")\n",
    "        traceGDF['video_location'] = videopath_sel[videopath_sel['video_id']==videoname]['video_location'].values[0]\n",
    "        traceGDF.drop('geometry', axis = 1).to_csv(os.path.join(stagingfolder, f\"{videoname}.csv\"), index = False)\n",
    "        # fullGDF.append(traceGDF)\n",
    "    except:\n",
    "        print(videoname, \": failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# stationary_frame = select_thred(0, unit = 'frame_id')\n",
    "# stationary_frame.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test visualize on the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoname = '20081008-141944b01'\n",
    "\n",
    "traceGDF = pd.read_csv(os.path.join(stagingfolder, f\"{videoname}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = traceGDF.groupby('track_id_backup')['track_id'].nunique().sort_values().reset_index()\n",
    "summary[summary['track_id']>1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = traceGDF[traceGDF['track_id_backup']==1069]\n",
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all video paths\n",
    "videofolder = \"/Users/yuan/Dropbox (MIT)/whyte_CV/_data/00_raw/videos_current_highres\"\n",
    "videos = glob.glob(os.path.join(videofolder, \"*/*.avi\"))\n",
    "videos2 = glob.glob(os.path.join(videofolder, \"*/*/*.avi\"))\n",
    "videos = videos+videos2\n",
    "# file_path = \"../data/00_raw/videos_current_highres/\"+videoname+\".avi\"\n",
    "# video, fps, size = getbasics(file_path)\n",
    "video_df = pd.DataFrame({\n",
    "    \"video_name\": [os.path.basename(x) for x in videos],\n",
    "    \"video_path\": videos,\n",
    "    \"video_id\": [os.path.basename(x).split(\".\")[0] for x in videos],\n",
    "})\n",
    "video_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# videoname = remain[-1]\n",
    "file_path = video_df[video_df[\"video_id\"]==videoname][\"video_path\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize by comparing the group activity and single activity\n",
    "def getbasics(file_path):\n",
    "    video = cv2.VideoCapture(file_path)\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    print('frames per second =',fps)\n",
    "    size = (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    print('frames size =',size)\n",
    "    # video.release()\n",
    "    return video, fps, size\n",
    "\n",
    "def compute_color_for_labels(label):\n",
    "    \"\"\"\n",
    "    Simple function that adds fixed color depending on the class\n",
    "    \"\"\"\n",
    "    palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n",
    "    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n",
    "    return tuple(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MET\n",
    "def load_met_pred(videoname):\n",
    "\n",
    "    result_folder = \"/Users/yuan/Dropbox (MIT)/whyte_CV/_data/03_tracking_result/_current_video_no_attr\"\n",
    "    predpath = os.path.join(result_folder, f'{videoname}.txt')\n",
    "    trace = pd.read_csv(predpath, sep = '\\t', header = None)\n",
    "    trace.columns = [ \"x1\", \"y1\", \"x2\", \"y2\", \"track_id\", \"frame_id\"]\n",
    "    trace['w'] = trace['x2'] - trace['x1']\n",
    "    trace['h'] = trace['y2'] - trace['y1']\n",
    "    trace['ratio'] = trace['w']/trace['h']\n",
    "    return trace\n",
    "\n",
    "def load_pred(videoname):\n",
    "    result_folder = \"../../_data/06_attr_result/\" # with attributes\n",
    "    # result_folder = '/Users/yuan/Dropbox (MIT)/whyte_CV/_data/03_tracking_result/_current_video_no_attr' # without attributes\n",
    "    # predpath = os.path.join(result_folder, f'{videoname}_attr_mot.csv')\n",
    "    predpath = os.path.join(result_folder, f'{videoname}.csv')\n",
    "    trace = pd.read_csv(predpath)\n",
    "    trace.rename(columns = {\"x\":\"bbox0\", \"y\":\"bbox1\", \"w\":\"bbox2\", \"h\":\"bbox3\"}, inplace = True)\n",
    "    for x in [\"bbox0\", \"bbox1\", \"bbox2\", \"bbox3\"]:\n",
    "        trace[x] = trace[x].astype(int)\n",
    "    # convert bbox to x,y\n",
    "    # trace['x1'] = trace['bbox0']\n",
    "    # trace['x2'] = trace['bbox0']+trace['bbox1']\n",
    "    # trace['y1'] = trace['bbox2']\n",
    "    # trace['y2'] = trace['bbox2']+trace['bbox3']\n",
    "    return trace\n",
    "\n",
    "\n",
    "# trace.rename(columns = {\"x1\":\"bbox0\", \"y1\":\"bbox1\", \"w\":\"bbox2\", \"h\":\"bbox3\"}, inplace = True)\n",
    "\n",
    "# trace['loc_x'] = (trace['bbox0'] + trace['bbox0'] + trace['bbox2'])/2\n",
    "# trace['loc_y'] = (trace['bbox1'] + trace['bbox3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace_sel_merg = trace.merge(sample, left_on = ['track_id', 'frame_id'], \n",
    "#                              right_on = ['track_id_backup', 'frame_id'], \n",
    "#                              how = 'inner')\n",
    "# trace_sel_merg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipfolder = \"../../_data/99_result_sample_export2\"\n",
    "if not os.path.exists(clipfolder):\n",
    "    os.makedirs(clipfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = video_df[video_df[\"video_id\"]==videoname][\"video_path\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "dur = sample['frame_id'].max() - sample['frame_id'].min() # second, change here for other options\n",
    "# startframe = int(newgroup[\"frame_id\"].min())\n",
    "startframe = sample['frame_id'].min()\n",
    "endframe = int(startframe + dur)\n",
    "\n",
    "# set startframe\n",
    "video, fps, size = getbasics(file_path)\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, startframe)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "video_out_name = videoname + f\"_{startframe}_{endframe}_group\"\n",
    "video_out = cv2.VideoWriter(os.path.join(clipfolder, \n",
    "                                         f\"{video_out_name}.mp4\"), fourcc, fps, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = True\n",
    "count = 0\n",
    "while ret and count<endframe:\n",
    "    ret, frame = video.read()\n",
    "    frame_id = count\n",
    "    # data = trace_sel_before_pro[trace_sel_before_pro[\"frame_id\"]==frame_id].reset_index(drop = True)\n",
    "    data = trace_sel_merg[trace_sel_merg['frame_id']==frame_id].reset_index(drop = True)\n",
    "    # only viz the stationary people\n",
    "    # data = temp[temp['stationary_1']==1].reset_index(drop = True)\n",
    "    \n",
    "    if data.shape[0]>0:\n",
    "        for i in range(data.shape[0]):\n",
    "            track_id = data.at[i,'track_id_update']+1\n",
    "            color = compute_color_for_labels(track_id)\n",
    "            # assign color to each track\n",
    "\n",
    "            cv2.rectangle(frame,\n",
    "                            (data.at[i,'x1'], \n",
    "                        data.at[i,'y1']), \n",
    "                        (data.at[i,'x2'], \n",
    "                        data.at[i,'y2']), \n",
    "                    color, 2)\n",
    "\n",
    "        \n",
    "    else:\n",
    "        print(\"no observation at frame\", frame_id)\n",
    "    if count>=startframe:\n",
    "        video_out.write(frame) \n",
    "    count = count+1\n",
    "    # print(ret)\n",
    "video_out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = load_pred(videoname)\n",
    "trace_sel_merg = trace.merge(sample, left_on = ['track_id', 'frame_id'], \n",
    "                             right_on = ['track_id_backup', 'frame_id'], \n",
    "                             how = 'inner')\n",
    "trace_sel_merg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "dur = sample['frame_id'].max() - sample['frame_id'].min() # second, change here for other options\n",
    "# startframe = int(newgroup[\"frame_id\"].min())\n",
    "startframe = sample['frame_id'].min()\n",
    "endframe = int(startframe + dur)\n",
    "\n",
    "# set startframe\n",
    "video, fps, size = getbasics(file_path)\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, startframe)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "video_out_name = videoname + f\"_{startframe}_{endframe}_group\"\n",
    "video_out = cv2.VideoWriter(os.path.join(clipfolder, \n",
    "                                         f\"{video_out_name}.mp4\"), fourcc, fps, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = True\n",
    "count = startframe\n",
    "while ret and count<endframe:\n",
    "    ret, frame = video.read()\n",
    "    frame_id = count\n",
    "    # data = trace_sel_before_pro[trace_sel_before_pro[\"frame_id\"]==frame_id].reset_index(drop = True)\n",
    "    data = trace_sel_merg[trace_sel_merg['frame_id']==frame_id].reset_index(drop = True)\n",
    "    # only viz the stationary people\n",
    "    # data = temp[temp['stationary_1']==1].reset_index(drop = True)\n",
    "    \n",
    "    if data.shape[0]>0:\n",
    "        for i in range(data.shape[0]):\n",
    "            track_id = data.at[i,'track_id_update']+1\n",
    "            color = compute_color_for_labels(track_id)\n",
    "            # assign color to each track\n",
    "\n",
    "            cv2.rectangle(frame,\n",
    "                            (data.at[i,'bbox0'], \n",
    "                        data.at[i,'bbox1']), \n",
    "                        (data.at[i,'bbox0']+data.at[i,'bbox2'], \n",
    "                        data.at[i,'bbox1']+data.at[i,'bbox3']), \n",
    "                    color, 2)\n",
    "\n",
    "        \n",
    "    else:\n",
    "        print(\"no observation at frame\", frame_id)\n",
    "    if count>=startframe:\n",
    "        video_out.write(frame) \n",
    "    count = count+1\n",
    "    # print(ret)\n",
    "video_out.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for stationary detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = True\n",
    "count = startframe\n",
    "frame_total = endframe - startframe\n",
    "\n",
    "while ret and count<=frame_total+startframe:\n",
    "    ret, frame = video.read()\n",
    "    frame_id = count\n",
    "    temp = vizdata[vizdata[\"frame_id\"]==frame_id].reset_index(drop = True)\n",
    "    # only viz the stationary people\n",
    "    data = temp[temp['stationary_3']==1].reset_index(drop = True)\n",
    "    if data.shape[0]>0:\n",
    "        for i in range(data.shape[0]):\n",
    "            track_id = data.at[i,'track_id']\n",
    "            cv2.rectangle(frame, \n",
    "                        (data.at[i,'bbox0'], \n",
    "                        data.at[i,'bbox1']), \n",
    "                        (data.at[i,'bbox0']+data.at[i,'bbox2'], \n",
    "                        data.at[i,'bbox1']+data.at[i,'bbox3']), \n",
    "                            (0,0,255), 2)\n",
    "            cv2.putText(\n",
    "                    frame, \n",
    "                    str(int(track_id)),\n",
    "                    (data.at[i,'bbox0'], data.at[i,'bbox1']-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, \n",
    "                    2,\n",
    "                    lineType=cv2.LINE_AA\n",
    "                )\n",
    "\n",
    "    # print(frame, ret)\n",
    "        \n",
    "    else:\n",
    "        print(\"no stationary at frame\", frame_id)\n",
    "    video_out.write(frame) \n",
    "    count = count+1\n",
    "    # print(ret)\n",
    "video_out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c624f5cd4f43ba04980739061df70c70943b2041a65fc94f85b2846fd2e789f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
